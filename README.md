# HackEVL 2025 - Behavioral Analyzer

A comprehensive real-time behavioral analysis system that combines computer vision, audio processing, and machine learning to analyze human behavior through video and audio streams.

## ğŸš€ Features

### Video Analysis
- **Multi-person Detection**: YOLO-based object detection to identify and track multiple people
- **Main Person Focus**: Automatically identifies and focuses analysis on the primary subject
- **Facial Emotion Recognition**: Real-time emotion detection using DeepFace
- **Eye Blink Detection**: Advanced blink detection with adaptive thresholds for fatigue analysis
- **Pose Analysis**: Body posture and movement tracking using MediaPipe
- **Attention Tracking**: Face orientation and gaze analysis

### Audio Analysis
- **Speech Transcription**: Real-time speech-to-text using Faster Whisper
- **Sentiment Analysis**: Text-based sentiment scoring and analysis
- **Audio Emotion Detection**: Prosodic feature-based emotion recognition
- **Speech Rate Analysis**: Speaking pace and rhythm analysis
- **Audio Feature Extraction**: Energy, pitch, and silence ratio analysis

### System Features
- **Real-time Processing**: Optimized for live video and audio streams
- **Modular Architecture**: Easy to extend with new analysis features
- **JSON Output**: Structured session data export
- **Clean Python Interface**: Command-line interface with live feedback
- **Performance Optimized**: Background processing threads for smooth operation

## ğŸ“‹ Requirements

### System Requirements
- **Python**: 3.12 or higher
- **Operating System**: macOS (optimized for Apple Silicon)
- **Camera**: Built-in or external webcam
- **Microphone**: Built-in or external microphone
- **RAM**: Minimum 8GB (16GB recommended)
- **Storage**: 2GB free space for models and dependencies

### Python Dependencies
```bash
# Core computer vision and ML
numpy>=1.24.0
opencv-python>=4.8.0
mediapipe>=0.10.0
tensorflow-macos>=2.13.0
tf-keras>=2.13.0
deepface>=0.0.79

# Object detection and tracking
ultralytics>=8.0.0
torch>=2.0.0
torchvision>=0.15.0

# Audio processing and speech recognition
sounddevice>=0.4.6
librosa>=0.10.0
faster-whisper>=0.9.0
textblob>=0.17.1

# Data processing
scipy>=1.10.0
pandas>=2.0.0
matplotlib>=3.7.0
pillow>=9.5.0

# Web interface (optional)
flask>=2.3.0
flask-socketio>=5.3.0
eventlet>=0.33.0
```

## ğŸ› ï¸ Installation

### Option 1: Using uv (Recommended)
```bash
# Install uv if you haven't already
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repository
git clone https://github.com/rachan2005/hackevl2025.git
cd hackevl2025/behavioral_analyzer

# Install dependencies
uv sync

# Run the behavioral analyzer
uv run python -m behavioral_analyzer
```

### Option 2: Using pip
```bash
# Clone the repository
git clone https://github.com/rachan2005/hackevl2025.git
cd hackevl2025

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the behavioral analyzer
cd behavioral_analyzer
python -m behavioral_analyzer
```

## ğŸ® Usage

### Basic Usage
```bash
# Run with default settings
uv run python -m behavioral_analyzer

# Or with pip
python -m behavioral_analyzer
```

### Controls
- **'q'** - Quit the application
- **'d'** - Toggle debug mode
- **'l'** - Toggle landmark display
- **'r'** - Start/stop recording
- **'s'** - Save session data
- **'h'** - Show help

### Output
- **Real-time Console**: Live analysis results and statistics
- **Session Data**: JSON files saved to `video/` directory
- **Video Recording**: MP4 files saved to `video/` directory (optional)

## ğŸ“Š Analysis Output

The system provides comprehensive behavioral analysis including:

### Video Metrics
- Person count and main person identification
- Real-time emotion detection (happy, sad, angry, fear, surprise, neutral)
- Eye blink rate and fatigue indicators
- Face orientation and attention level
- Pose landmarks and body movement

### Audio Metrics
- Speech transcription with word-level timing
- Sentiment analysis scores (-1.0 to 1.0)
- Audio emotion detection
- Speech rate and rhythm analysis
- Energy, pitch, and silence ratio

### Session Summary
- Overall session duration and statistics
- Final emotion and attention states
- Average processing FPS
- Comprehensive behavioral insights

## ğŸ—ï¸ Architecture

```
behavioral_analyzer/
â”œâ”€â”€ behavioral_analyzer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â”œâ”€â”€ video_analyzer.py      # Video analysis engine
â”‚   â”œâ”€â”€ audio_analyzer.py      # Audio analysis engine
â”‚   â”œâ”€â”€ object_detector.py     # YOLO object detection
â”‚   â”œâ”€â”€ unified_analyzer.py    # Main orchestrator
â”‚   â”œâ”€â”€ web_ui.py             # Web dashboard (optional)
â”‚   â””â”€â”€ utils.py              # Utility functions
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ examples/                 # Example scripts
â”œâ”€â”€ static/                   # Web UI assets
â”œâ”€â”€ templates/                # Web UI templates
â”œâ”€â”€ pyproject.toml           # Project configuration
â””â”€â”€ requirements.txt         # Dependencies
```

## ğŸ”§ Configuration

Key configuration options in `config.py`:

```python
# Video Analysis
enable_object_detection = True
yolo_model_size = "n"  # nano, small, medium, large, xlarge
yolo_confidence_threshold = 0.5

# Audio Analysis
whisper_model_size = "tiny.en"
audio_sample_rate = 16000

# Performance
max_fps = 30
emotion_detection_interval = 0.5
```

## ğŸš€ Performance

- **Processing Speed**: ~12-15 FPS on Apple M2
- **Memory Usage**: ~2-4GB RAM
- **Latency**: <100ms for real-time analysis
- **Accuracy**: >90% emotion detection accuracy

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **MediaPipe** for facial landmark detection
- **DeepFace** for emotion recognition
- **Ultralytics YOLO** for object detection
- **Faster Whisper** for speech recognition
- **OpenCV** for computer vision operations

## ğŸ“ Support

For questions or issues, please open an issue on GitHub or contact the HackEVL 2025 team.

---

**Built with â¤ï¸ for HackEVL 2025**
